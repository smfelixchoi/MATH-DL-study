{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "297e296f",
   "metadata": {},
   "source": [
    "# DCGAN - PyTorch using MNIST\n",
    "\n",
    "### 작성자: 고려대학교 수학과 석사과정 최선묵\n",
    "\n",
    "[References]  \n",
    "- [Goodfellow's GAN Paper Link](https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf)  \n",
    "- [DCGAN Paper Link](https://arxiv.org/pdf/1511.06434.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76463fb3",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "986b184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76f995fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import ReLU, LeakyReLU, Reshape\n",
    "from tensorflow.keras.layers import BatchNormalization, Flatten\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a955ffdf",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddff9f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_image(batch_size=32):\n",
    "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "    \n",
    "    # Add the color channel - change to 4D tensor, and convert the data type to 'float32'\n",
    "    train_images = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32')\n",
    "    \n",
    "    # Set the pixel values from -1 to 1\n",
    "    train_images = (train_images/255.0) * 2 - 1\n",
    "    \n",
    "    # Shuffle and separate in batch\n",
    "    buffer_size = train_images.shape[0]\n",
    "    train_images_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(buffer_size).batch(batch_size)\n",
    "    \n",
    "    return train_images_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4edd06",
   "metadata": {},
   "source": [
    "### Hyperparameters for latent codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c69452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise\n",
    "noise_dim = 62"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca86f5a3",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cba7fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator(n_filters=128, input_size=noise_dim):\n",
    "    # Build functional API model\n",
    "    # input\n",
    "    input_tensor = Input(shape=(input_size, ))\n",
    "\n",
    "    # Fully-connected layer.\n",
    "    x = Dense(units=1024, use_bias=False, kernel_initializer='he_uniform') (input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Fully-connected layer. The output should be able to reshape into 7x7\n",
    "    x = Dense(units=7*7*128, use_bias=False, kernel_initializer='he_uniform') (x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Reshape\n",
    "    x = Reshape(target_shape=(7, 7, 128))(x)\n",
    "\n",
    "    nf = n_filters\n",
    "    # First transposed convolutional layer\n",
    "\n",
    "    x = Conv2DTranspose(nf, kernel_size=(4, 4), strides=(2, 2), padding='same', \n",
    "                        use_bias=False, kernel_initializer='he_uniform')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # Number of filters halved after each transposed convolutional layer\n",
    "    nf = nf//2\n",
    "    \n",
    "    # Second transposed convolutional layer\n",
    "    # strides=(2, 2): shape is doubled after the transposed convolution\n",
    "    x = Conv2DTranspose(nf, kernel_size=(4, 4), strides=(2, 2), padding='same', \n",
    "                        use_bias=False, kernel_initializer='he_uniform')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # Final transposed convolutional layer: output shape: 28x28x1, tanh activation\n",
    "    output = Conv2DTranspose(1, kernel_size=(4, 4), strides=(1, 1), padding=\"same\", \n",
    "                             activation=\"tanh\", kernel_initializer='glorot_uniform')(x)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73a58c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 62)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              63488     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6272)              6422528   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 6272)              25088     \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 14, 14, 128)       262144    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 64)        131072    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         1025      \n",
      "=================================================================\n",
      "Total params: 6,910,209\n",
      "Trainable params: 6,895,233\n",
      "Non-trainable params: 14,976\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "g_model = create_generator()\n",
    "g_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3b53bc",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13af48ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator(n_filters=64, input_shape=(28, 28, 1)):\n",
    "    # Build functional API model\n",
    "    # Image Input\n",
    "    image_input = Input(shape=input_shape)\n",
    "\n",
    "    nf = n_filters\n",
    "    \n",
    "    x = Conv2D(nf, kernel_size=(4, 4), strides=(2, 2), padding=\"same\", use_bias=True)(image_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    # Number of filters doubled after each convolutional layer\n",
    "    nf = nf*2\n",
    "    \n",
    "    # Second convolutional layer\n",
    "    # Output shape: 7x7\n",
    "    x = Conv2D(nf, kernel_size=(4, 4), strides=(2, 2), padding=\"same\", use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    # Flatten the convolutional layers\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # FC layer\n",
    "    x = Dense(1024, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    # Discriminator output. Sigmoid activation function to classify \"True\" or \"False\"\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    # Discriminator model (not compiled)\n",
    "    d_model = Model(inputs=image_input, outputs=output)\n",
    "    \n",
    "    return d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ffd7b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 14, 14, 64)        1088      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 128)         131072    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              6422528   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 6,560,577\n",
      "Trainable params: 6,558,145\n",
      "Non-trainable params: 2,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "d_model = create_discriminator()\n",
    "d_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4195d354",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(tf.keras.Model):\n",
    "    def __init__(self, d_model, g_model, noise_size=noise_dim, d_iter=1, seed=None):\n",
    "        super(GAN, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.g_model = g_model\n",
    "        self.noise_size = noise_size\n",
    "        self.d_iter = d_iter\n",
    "        self.seed = seed\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "\n",
    "    def create_gen_input(self, batch_size, seed):\n",
    "        noise = tf.random.normal([batch_size, self.noise_size], seed=seed)\n",
    "        return noise\n",
    "\n",
    "    def train_step(self, real_image_batch):\n",
    "        \n",
    "        # Define loss functions\n",
    "        binary_loss = BinaryCrossentropy()\n",
    "#         categorical_loss = CategoricalCrossentropy()\n",
    "        \n",
    "        # Half-batch for training discriminator and batch for training generator and auxiliary model\n",
    "        batch_size = tf.shape(real_image_batch)[0]\n",
    "        \n",
    "        # Create generator input \n",
    "        g_noise = self.create_gen_input(batch_size=batch_size, seed=self.seed)\n",
    "#         g_input = self.concat_inputs([g_cat, g_conti, g_noise])\n",
    "        \n",
    "        for _ in range(self.d_iter):\n",
    "            with tf.GradientTape() as d_tape: \n",
    "                self.d_model.trainable = True\n",
    "                d_tape.watch(self.d_model.trainable_variables)\n",
    "\n",
    "                # Train discriminator using half batch real images. Real images have labels 1.\n",
    "                y_disc_real = tf.ones((batch_size, 1))\n",
    "                d_real_output = self.d_model(real_image_batch, training=True)\n",
    "                d_loss_real = binary_loss(y_disc_real, d_real_output)\n",
    "\n",
    "                # Train discriminator using half batch fake images. Fake images have labels 0. \n",
    "                y_disc_fake = tf.zeros((batch_size, 1))\n",
    "\n",
    "                # Create fake image batch\n",
    "                fake_image_batch = self.g_model(g_noise, training=True)\n",
    "                d_fake_output = self.d_model(fake_image_batch, training=True)\n",
    "                d_loss_fake = binary_loss(y_disc_fake, d_fake_output)\n",
    "\n",
    "                # Total Loss of Discriminator \n",
    "                d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "            # Calculate gradients\n",
    "            d_gradients = d_tape.gradient(d_loss, self.d_model.trainable_variables)\n",
    "\n",
    "            # Optimize\n",
    "            self.d_optimizer.apply_gradients(zip(d_gradients, self.d_model.trainable_variables))\n",
    "\n",
    "        with tf.GradientTape() as g_tape:\n",
    "            # Create generator input \n",
    "            g_noise = self.create_gen_input(batch_size=batch_size*2, seed=self.seed)\n",
    "            \n",
    "            g_tape.watch(self.g_model.trainable_variables)\n",
    "            \n",
    "            # Create fake image batch\n",
    "            fake_image_batch = self.g_model(g_noise, training=True)\n",
    "            d_fake_output = self.d_model(fake_image_batch, training=True)\n",
    "            \n",
    "            # Generator Image loss\n",
    "            y_gen_fake = tf.ones((batch_size*2, 1))\n",
    "            \n",
    "            g_loss = binary_loss(y_gen_fake, d_fake_output)\n",
    "            \n",
    "            \n",
    "        # Calculate gradients\n",
    "        # We do not want to modify the neurons in the discriminator when training the generator and the auxiliary model\n",
    "        self.d_model.trainable=False\n",
    "        g_gradients = g_tape.gradient(g_loss, self.g_model.trainable_variables)\n",
    "        \n",
    "        # Optimize\n",
    "        self.g_optimizer.apply_gradients(zip(g_gradients, self.g_model.trainable_variables))\n",
    "\n",
    "        return {\"d_loss_real\": d_loss_real, \"d_loss_fake\": d_loss_fake, \"g_loss\": g_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f62fddd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1875/1875 [==============================] - 33s 11ms/step - d_loss_real: 0.1397 - d_loss_fake: 0.1960 - g_loss: 2.7078\n",
      "Epoch 2/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.1199 - d_loss_fake: 0.1126 - g_loss: 3.6948\n",
      "Epoch 3/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.4299 - d_loss_fake: 0.4106 - g_loss: 1.7906\n",
      "Epoch 4/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.6156 - d_loss_fake: 0.6072 - g_loss: 0.9320\n",
      "Epoch 5/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.6238 - d_loss_fake: 0.6181 - g_loss: 0.8991\n",
      "Epoch 6/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.6195 - d_loss_fake: 0.6153 - g_loss: 0.9038\n",
      "Epoch 7/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.6066 - d_loss_fake: 0.6039 - g_loss: 0.9338\n",
      "Epoch 8/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.5985 - d_loss_fake: 0.5953 - g_loss: 0.9558\n",
      "Epoch 9/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.5879 - d_loss_fake: 0.5861 - g_loss: 0.9817\n",
      "Epoch 10/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.5814 - d_loss_fake: 0.5802 - g_loss: 0.9999\n",
      "Epoch 11/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.5754 - d_loss_fake: 0.5740 - g_loss: 1.0217\n",
      "Epoch 12/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.5734 - d_loss_fake: 0.5706 - g_loss: 1.0374\n",
      "Epoch 13/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.5592 - d_loss_fake: 0.5584 - g_loss: 1.0718\n",
      "Epoch 14/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.5543 - d_loss_fake: 0.5519 - g_loss: 1.1025\n",
      "Epoch 15/80\n",
      "1875/1875 [==============================] - 22s 11ms/step - d_loss_real: 0.5442 - d_loss_fake: 0.5403 - g_loss: 1.1257\n",
      "Epoch 16/80\n",
      "1875/1875 [==============================] - 22s 11ms/step - d_loss_real: 0.5177 - d_loss_fake: 0.5142 - g_loss: 1.2134\n",
      "Epoch 17/80\n",
      "1875/1875 [==============================] - 22s 11ms/step - d_loss_real: 0.5276 - d_loss_fake: 0.5247 - g_loss: 1.1810\n",
      "Epoch 18/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.5229 - d_loss_fake: 0.5222 - g_loss: 1.2072\n",
      "Epoch 19/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.5186 - d_loss_fake: 0.5152 - g_loss: 1.2290\n",
      "Epoch 20/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.5075 - d_loss_fake: 0.5058 - g_loss: 1.2723\n",
      "Epoch 21/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.5064 - d_loss_fake: 0.5038 - g_loss: 1.2953\n",
      "Epoch 22/80\n",
      "1875/1875 [==============================] - 22s 11ms/step - d_loss_real: 0.4985 - d_loss_fake: 0.4963 - g_loss: 1.3179\n",
      "Epoch 23/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.4908 - d_loss_fake: 0.4888 - g_loss: 1.3528\n",
      "Epoch 24/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.4871 - d_loss_fake: 0.4871 - g_loss: 1.3782\n",
      "Epoch 25/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.4770 - d_loss_fake: 0.4756 - g_loss: 1.4128\n",
      "Epoch 26/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.4735 - d_loss_fake: 0.4722 - g_loss: 1.4520\n",
      "Epoch 27/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.4617 - d_loss_fake: 0.4610 - g_loss: 1.4832\n",
      "Epoch 28/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.4562 - d_loss_fake: 0.4576 - g_loss: 1.5086\n",
      "Epoch 29/80\n",
      "1875/1875 [==============================] - 22s 11ms/step - d_loss_real: 0.4535 - d_loss_fake: 0.4541 - g_loss: 1.5371\n",
      "Epoch 30/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.4424 - d_loss_fake: 0.4426 - g_loss: 1.5846\n",
      "Epoch 31/80\n",
      "1875/1875 [==============================] - 22s 11ms/step - d_loss_real: 0.4404 - d_loss_fake: 0.4416 - g_loss: 1.5928\n",
      "Epoch 32/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.4340 - d_loss_fake: 0.4321 - g_loss: 1.6471\n",
      "Epoch 33/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.4273 - d_loss_fake: 0.4270 - g_loss: 1.6780\n",
      "Epoch 34/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.4247 - d_loss_fake: 0.4257 - g_loss: 1.7115\n",
      "Epoch 35/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.4191 - d_loss_fake: 0.4216 - g_loss: 1.7272\n",
      "Epoch 36/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.4165 - d_loss_fake: 0.4196 - g_loss: 1.7694\n",
      "Epoch 37/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.4124 - d_loss_fake: 0.4135 - g_loss: 1.7869\n",
      "Epoch 38/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.4022 - d_loss_fake: 0.4054 - g_loss: 1.8201\n",
      "Epoch 39/80\n",
      "1875/1875 [==============================] - 22s 11ms/step - d_loss_real: 0.3980 - d_loss_fake: 0.4019 - g_loss: 1.8674\n",
      "Epoch 40/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.3932 - d_loss_fake: 0.3966 - g_loss: 1.8953\n",
      "Epoch 41/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.3850 - d_loss_fake: 0.3869 - g_loss: 1.9302\n",
      "Epoch 42/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.3827 - d_loss_fake: 0.3856 - g_loss: 1.9616\n",
      "Epoch 43/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.3761 - d_loss_fake: 0.3782 - g_loss: 1.9766\n",
      "Epoch 44/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.3753 - d_loss_fake: 0.3779 - g_loss: 2.0307\n",
      "Epoch 45/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.3676 - d_loss_fake: 0.3725 - g_loss: 2.0618\n",
      "Epoch 46/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.3648 - d_loss_fake: 0.3652 - g_loss: 2.1016\n",
      "Epoch 47/80\n",
      "1875/1875 [==============================] - 22s 12ms/step - d_loss_real: 0.3570 - d_loss_fake: 0.3573 - g_loss: 2.1511\n",
      "Epoch 48/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.3571 - d_loss_fake: 0.3630 - g_loss: 2.1542\n",
      "Epoch 49/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.3552 - d_loss_fake: 0.3600 - g_loss: 2.1765\n",
      "Epoch 50/80\n",
      "1875/1875 [==============================] - 22s 11ms/step - d_loss_real: 0.3530 - d_loss_fake: 0.3592 - g_loss: 2.2134\n",
      "Epoch 51/80\n",
      "1875/1875 [==============================] - 22s 12ms/step - d_loss_real: 0.3470 - d_loss_fake: 0.3520 - g_loss: 2.2404\n",
      "Epoch 52/80\n",
      "1875/1875 [==============================] - 22s 11ms/step - d_loss_real: 0.3405 - d_loss_fake: 0.3457 - g_loss: 2.2722\n",
      "Epoch 53/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.3375 - d_loss_fake: 0.3429 - g_loss: 2.3214\n",
      "Epoch 54/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.3396 - d_loss_fake: 0.3426 - g_loss: 2.3386\n",
      "Epoch 55/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.3256 - d_loss_fake: 0.3300 - g_loss: 2.3858\n",
      "Epoch 56/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.3264 - d_loss_fake: 0.3308 - g_loss: 2.4156\n",
      "Epoch 57/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.3190 - d_loss_fake: 0.3248 - g_loss: 2.4415\n",
      "Epoch 58/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.3197 - d_loss_fake: 0.3267 - g_loss: 2.4585\n",
      "Epoch 59/80\n",
      "1875/1875 [==============================] - 22s 11ms/step - d_loss_real: 0.3124 - d_loss_fake: 0.3186 - g_loss: 2.5039\n",
      "Epoch 60/80\n",
      "1875/1875 [==============================] - 22s 11ms/step - d_loss_real: 0.3142 - d_loss_fake: 0.3202 - g_loss: 2.5212\n",
      "Epoch 61/80\n",
      "1875/1875 [==============================] - 22s 12ms/step - d_loss_real: 0.3054 - d_loss_fake: 0.3111 - g_loss: 2.5743\n",
      "Epoch 62/80\n",
      "1875/1875 [==============================] - 22s 11ms/step - d_loss_real: 0.3027 - d_loss_fake: 0.3102 - g_loss: 2.6481\n",
      "Epoch 63/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.3051 - d_loss_fake: 0.3096 - g_loss: 2.6015\n",
      "Epoch 64/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.2972 - d_loss_fake: 0.3062 - g_loss: 2.6517\n",
      "Epoch 65/80\n",
      "1875/1875 [==============================] - 22s 11ms/step - d_loss_real: 0.2972 - d_loss_fake: 0.3031 - g_loss: 2.6513\n",
      "Epoch 66/80\n",
      "1875/1875 [==============================] - 22s 11ms/step - d_loss_real: 0.2955 - d_loss_fake: 0.3025 - g_loss: 2.7114\n",
      "Epoch 67/80\n",
      "1875/1875 [==============================] - 22s 11ms/step - d_loss_real: 0.2904 - d_loss_fake: 0.2973 - g_loss: 2.7200\n",
      "Epoch 68/80\n",
      "1875/1875 [==============================] - 22s 11ms/step - d_loss_real: 0.2846 - d_loss_fake: 0.2908 - g_loss: 2.7912\n",
      "Epoch 69/80\n",
      "1875/1875 [==============================] - 22s 11ms/step - d_loss_real: 0.2837 - d_loss_fake: 0.2943 - g_loss: 2.7878\n",
      "Epoch 70/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.2775 - d_loss_fake: 0.2852 - g_loss: 2.8412\n",
      "Epoch 71/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.2760 - d_loss_fake: 0.2840 - g_loss: 2.8916\n",
      "Epoch 72/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.2712 - d_loss_fake: 0.2773 - g_loss: 2.9075\n",
      "Epoch 73/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.2715 - d_loss_fake: 0.2803 - g_loss: 2.9262\n",
      "Epoch 74/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.2691 - d_loss_fake: 0.2766 - g_loss: 2.9689\n",
      "Epoch 75/80\n",
      "1875/1875 [==============================] - 22s 12ms/step - d_loss_real: 0.2615 - d_loss_fake: 0.2694 - g_loss: 2.9932\n",
      "Epoch 76/80\n",
      "1875/1875 [==============================] - 22s 11ms/step - d_loss_real: 0.2594 - d_loss_fake: 0.2694 - g_loss: 3.0541\n",
      "Epoch 77/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.2580 - d_loss_fake: 0.2681 - g_loss: 3.0705\n",
      "Epoch 78/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.2546 - d_loss_fake: 0.2616 - g_loss: 3.0989\n",
      "Epoch 79/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.2568 - d_loss_fake: 0.2645 - g_loss: 3.1004\n",
      "Epoch 80/80\n",
      "1875/1875 [==============================] - 21s 11ms/step - d_loss_real: 0.2509 - d_loss_fake: 0.2599 - g_loss: 3.1414\n"
     ]
    }
   ],
   "source": [
    "gan = GAN(d_model, g_model)\n",
    "\n",
    "gan.compile(d_optimizer=Adam(learning_rate=2e-4),\n",
    "            g_optimizer=Adam(learning_rate=5e-4))\n",
    "\n",
    "real_images = load_real_image(batch_size=32)\n",
    "\n",
    "history = gan.fit(real_images, epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9be4550b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/generator/assets\n",
      "INFO:tensorflow:Assets written to: saved_models/discriminator/assets\n"
     ]
    }
   ],
   "source": [
    "g_model.save('saved_models/generator')\n",
    "d_model.save('saved_models/discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49bf1bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "g_model = tf.keras.models.load_model('saved_models/generator')\n",
    "d_model = tf.keras.models.load_model('saved_models/discriminator')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9291ab",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "146a89d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "078419a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([10, 62], seed=831)\n",
    "\n",
    "x = g_model(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05e629c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (15.0, 8.0)\n",
    "\n",
    "rows = 2\n",
    "columns = 5\n",
    "\n",
    "for i in range(10) : \n",
    "    image_index = i      # image index \n",
    "    title = \"Sample {}\".format(image_index) # image title\n",
    "    plt.subplot(rows, columns, image_index+1) # subplot \n",
    "    plt.title(title)   # title \n",
    "    # // plt.axis('off')\n",
    "    plt.xticks([])  # x = None \n",
    "    plt.yticks([])  # y = None\n",
    "    plt.imshow(x[i], cmap=plt.get_cmap('gray'))  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae41b027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc4e322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2.4_p37)",
   "language": "python",
   "name": "conda_tensorflow2.4_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
