{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0decea1",
   "metadata": {},
   "source": [
    "# ResNet Implementation with PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c438aa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchsummary import summary\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "746d9501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26121aef",
   "metadata": {},
   "source": [
    "## Download CIFAR10 & Define DataLoader\n",
    "\n",
    "- `ToTensor()` transforms data into `Tensor` type and also normalizes into `[0,1]` range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33b14c93",
   "metadata": {
    "id": "d6kxGFAqIETZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "dataset = CIFAR10(root='', train=True, download=True, transform=transform)\n",
    "testset = CIFAR10(root='', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bfabb8d",
   "metadata": {
    "id": "N82C-hZPI3D5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6df86e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a25bd687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d81a58b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = int(len(dataset)*0.9)\n",
    "valid_num = len(dataset) - train_num\n",
    "\n",
    "trainset, validset = random_split(dataset, [train_num, valid_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aac73e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "validloader = DataLoader(validset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253146cc",
   "metadata": {},
   "source": [
    "## Construct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b6ebab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        \n",
    "        self.residual = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, out_planes, kernel_size=(3,3), stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_planes),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_planes, out_planes, kernel_size=(3,3), stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_planes)\n",
    "        )\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        if stride != 1 or in_planes != out_planes:\n",
    "            self.shortcut.add_module('conv', nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=True))                                     \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.residual(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c166308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "숙제!\n",
    "'''\n",
    "\n",
    "class BottleNeck(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride=1):\n",
    "        super(BottleNeck, self).__init__()\n",
    "        \n",
    "        self.residual = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, out_planes//4, kernel_size=(1,1), stride=stride, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(out_planes//4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_planes//4, out_planes//4, kernel_size=(3,3), stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_planes//4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_planes//4, out_planes, kernel_size=(1,1), stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(out_planes)\n",
    "        )\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        if stride != 1 or in_planes != out_planes:\n",
    "            self.shortcut.add_module('conv', nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=True))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.residual(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "18eb7781",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, channels, init_weights=True):\n",
    "        super(ResNet,self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(3, channels[0], kernel_size=7, stride=1, padding=3, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(channels[0])\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.block1 = BasicBlock(channels[0], channels[0], stride=1)\n",
    "        self.block2 = BasicBlock(channels[0], channels[1], stride=2)\n",
    "        self.block3 = BasicBlock(channels[1], channels[2], stride=1)\n",
    "        self.block4 = BasicBlock(channels[2], channels[3], stride=2)\n",
    "        self.block5 = BasicBlock(channels[3], channels[4], stride=2)\n",
    "        self.block6 = BasicBlock(channels[4], channels[4], stride=1)\n",
    "        \n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=(4,4))\n",
    "        \n",
    "        self.fc1 = nn.Linear(channels[4], channels[4]//4, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(channels[4]//4)\n",
    "        self.fc2 = nn.Linear(channels[4]//4, 10, bias=True)\n",
    "        \n",
    "        if init_weights:\n",
    "            self.initialize_weights()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.block1(x)      \n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = self.block6(x)        \n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias,0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "344164d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(channels=[16,16,32,64,128]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f389695c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]           2,352\n",
      "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
      "              ReLU-3           [-1, 16, 32, 32]               0\n",
      "            Conv2d-4           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-5           [-1, 16, 32, 32]              32\n",
      "              ReLU-6           [-1, 16, 32, 32]               0\n",
      "            Conv2d-7           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-8           [-1, 16, 32, 32]              32\n",
      "              ReLU-9           [-1, 16, 32, 32]               0\n",
      "       BasicBlock-10           [-1, 16, 32, 32]               0\n",
      "           Conv2d-11           [-1, 16, 16, 16]           2,304\n",
      "      BatchNorm2d-12           [-1, 16, 16, 16]              32\n",
      "             ReLU-13           [-1, 16, 16, 16]               0\n",
      "           Conv2d-14           [-1, 16, 16, 16]           2,304\n",
      "      BatchNorm2d-15           [-1, 16, 16, 16]              32\n",
      "           Conv2d-16           [-1, 16, 16, 16]             272\n",
      "             ReLU-17           [-1, 16, 16, 16]               0\n",
      "       BasicBlock-18           [-1, 16, 16, 16]               0\n",
      "           Conv2d-19           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-20           [-1, 32, 16, 16]              64\n",
      "             ReLU-21           [-1, 32, 16, 16]               0\n",
      "           Conv2d-22           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-23           [-1, 32, 16, 16]              64\n",
      "           Conv2d-24           [-1, 32, 16, 16]             544\n",
      "             ReLU-25           [-1, 32, 16, 16]               0\n",
      "       BasicBlock-26           [-1, 32, 16, 16]               0\n",
      "           Conv2d-27             [-1, 64, 8, 8]          18,432\n",
      "      BatchNorm2d-28             [-1, 64, 8, 8]             128\n",
      "             ReLU-29             [-1, 64, 8, 8]               0\n",
      "           Conv2d-30             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-31             [-1, 64, 8, 8]             128\n",
      "           Conv2d-32             [-1, 64, 8, 8]           2,112\n",
      "             ReLU-33             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-34             [-1, 64, 8, 8]               0\n",
      "           Conv2d-35            [-1, 128, 4, 4]          73,728\n",
      "      BatchNorm2d-36            [-1, 128, 4, 4]             256\n",
      "             ReLU-37            [-1, 128, 4, 4]               0\n",
      "           Conv2d-38            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-39            [-1, 128, 4, 4]             256\n",
      "           Conv2d-40            [-1, 128, 4, 4]           8,320\n",
      "             ReLU-41            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-42            [-1, 128, 4, 4]               0\n",
      "           Conv2d-43            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-44            [-1, 128, 4, 4]             256\n",
      "             ReLU-45            [-1, 128, 4, 4]               0\n",
      "           Conv2d-46            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-47            [-1, 128, 4, 4]             256\n",
      "             ReLU-48            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-49            [-1, 128, 4, 4]               0\n",
      "        AvgPool2d-50            [-1, 128, 1, 1]               0\n",
      "           Linear-51                   [-1, 32]           4,096\n",
      "      BatchNorm1d-52                   [-1, 32]              64\n",
      "             ReLU-53                   [-1, 32]               0\n",
      "           Linear-54                   [-1, 10]             330\n",
      "================================================================\n",
      "Total params: 614,090\n",
      "Trainable params: 614,090\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.49\n",
      "Params size (MB): 2.34\n",
      "Estimated Total Size (MB): 4.84\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,input_size=(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "032f5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-02.\n"
     ]
    }
   ],
   "source": [
    "loss_ftn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
    "                                        lr_lambda=lambda epoch: 0.95 ** epoch,\n",
    "                                        last_epoch=-1,\n",
    "                                        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e4f7749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, validloader, epochs, device, loss_ftn, optimizer, scheduler=None, temperature=None):\n",
    "    losses = []\n",
    "    accs = []\n",
    "    valid_losses = []\n",
    "    valid_accs = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        valid_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        valid_correct = 0\n",
    "        valid_total = 0\n",
    "        num_iter = 0\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = loss_ftn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            num_iter += 1\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = (correct/total)*100\n",
    "        losses.append(running_loss/num_iter)\n",
    "        accs.append(accuracy)\n",
    "        \n",
    "        valid_num_iter = 0\n",
    "        with torch.no_grad():\n",
    "            for data in validloader:\n",
    "                images, labels = data\n",
    "\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # calculate outputs by running images through the network\n",
    "                outputs = net(images)\n",
    "                loss = loss_ftn(outputs, labels)\n",
    "                \n",
    "                valid_num_iter += 1\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "                # the class with the highest energy is what we choose as prediction\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                valid_total += labels.size(0)\n",
    "                valid_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        valid_accuracy = (valid_correct/valid_total)*100\n",
    "        valid_losses.append(valid_loss/valid_num_iter)\n",
    "        valid_accs.append(valid_accuracy)\n",
    "\n",
    "        print('EPOCH %d Completed. \\n Training Loss: %.3f, Training Accuracy: %.2f, Validation Loss: %.3f, Validation Accuracy: %.2f \\n' \n",
    "              %(epoch+1, running_loss/num_iter, accuracy, valid_loss/valid_num_iter, valid_accuracy))\n",
    "            \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "                        \n",
    "    return losses, accs, valid_losses, valid_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e9d823b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, testloader, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)\n",
    "\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on 10000 test images: {100 * correct / total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4cabcf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 Completed. \n",
      " Training Loss: 1.706, Training Accuracy: 36.55, Validation Loss: 1.494, Validation Accuracy: 45.50 \n",
      "\n",
      "Adjusting learning rate of group 0 to 9.5000e-03.\n",
      "EPOCH 2 Completed. \n",
      " Training Loss: 1.316, Training Accuracy: 52.24, Validation Loss: 1.193, Validation Accuracy: 58.50 \n",
      "\n",
      "Adjusting learning rate of group 0 to 9.0250e-03.\n",
      "EPOCH 3 Completed. \n",
      " Training Loss: 1.061, Training Accuracy: 62.54, Validation Loss: 1.057, Validation Accuracy: 63.40 \n",
      "\n",
      "Adjusting learning rate of group 0 to 8.5737e-03.\n",
      "EPOCH 4 Completed. \n",
      " Training Loss: 0.902, Training Accuracy: 67.98, Validation Loss: 0.919, Validation Accuracy: 68.86 \n",
      "\n",
      "Adjusting learning rate of group 0 to 8.1451e-03.\n",
      "EPOCH 5 Completed. \n",
      " Training Loss: 0.774, Training Accuracy: 72.74, Validation Loss: 0.813, Validation Accuracy: 72.22 \n",
      "\n",
      "Adjusting learning rate of group 0 to 7.7378e-03.\n",
      "EPOCH 6 Completed. \n",
      " Training Loss: 0.666, Training Accuracy: 76.80, Validation Loss: 0.798, Validation Accuracy: 72.74 \n",
      "\n",
      "Adjusting learning rate of group 0 to 7.3509e-03.\n",
      "EPOCH 7 Completed. \n",
      " Training Loss: 0.577, Training Accuracy: 79.92, Validation Loss: 0.747, Validation Accuracy: 74.96 \n",
      "\n",
      "Adjusting learning rate of group 0 to 6.9834e-03.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcafb761820>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/mathdl/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/envs/mathdl/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/anaconda3/envs/mathdl/lib/python3.8/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/opt/anaconda3/envs/mathdl/lib/python3.8/multiprocessing/popen_fork.py\", line 44, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/opt/anaconda3/envs/mathdl/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/anaconda3/envs/mathdl/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [59], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m EPOCHS\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m\n\u001b[0;32m----> 3\u001b[0m losses, accs, valid_losses, valid_accs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mloss_ftn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [57], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, trainloader, validloader, epochs, device, loss_ftn, optimizer, scheduler, temperature)\u001b[0m\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_ftn(outputs, labels)\n\u001b[1;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 27\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m num_iter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     30\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mathdl/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:67\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     66\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mathdl/lib/python3.8/site-packages/torch/autograd/grad_mode.py:26\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m():\n\u001b[0;32m---> 26\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mathdl/lib/python3.8/site-packages/torch/optim/adam.py:108\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    107\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 108\u001b[0m     \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m           \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m           \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m           \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m           \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m           \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m           \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m           \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mathdl/lib/python3.8/site-packages/torch/optim/functional.py:86\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     83\u001b[0m     grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39madd(param, alpha\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amsgrad:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# Maintains the maximum of all 2nd moment running avg. till now\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS=30\n",
    "\n",
    "losses, accs, valid_losses, valid_accs = train(model, trainloader, validloader, EPOCHS, device, \n",
    "                                               loss_ftn, optimizer, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2af725b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 8.78 %\n"
     ]
    }
   ],
   "source": [
    "test(model, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "96d4cae9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [64], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(EPOCHS), \u001b[43mlosses\u001b[49m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(EPOCHS), valid_losses)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'losses' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(EPOCHS), losses)\n",
    "plt.plot(np.arange(EPOCHS), valid_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652e52a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MathDLstudy",
   "language": "python",
   "name": "mathdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
