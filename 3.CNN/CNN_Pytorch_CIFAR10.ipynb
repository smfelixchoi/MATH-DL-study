{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aENjWha3KApZ"
   },
   "source": [
    "# Convolutional Neural Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "c8EdXUqvIEVe"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchsummary import summary\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download MNIST & Define DataLoader\n",
    "\n",
    "- `ToTensor()` transforms data into `Tensor` type and also normalizes into `[0,1]` range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "d6kxGFAqIETZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /Users/sm/Documents/Codes/MATH-DL-study/3.CNN/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/sm/Documents/Codes/MATH-DL-study/3.CNN/cifar-10-python.tar.gz to /Users/sm/Documents/Codes/MATH-DL-study/3.CNN/\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "dataset = CIFAR10(root='/Users/sm/Documents/Codes/MATH-DL-study/3.CNN/', train=True, download=True, transform=transform)\n",
    "testset = CIFAR10(root='/Users/sm/Documents/Codes/MATH-DL-study/3.CNN/', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "N82C-hZPI3D5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 59,  62,  63],\n",
       "        [ 43,  46,  45],\n",
       "        [ 50,  48,  43],\n",
       "        ...,\n",
       "        [158, 132, 108],\n",
       "        [152, 125, 102],\n",
       "        [148, 124, 103]],\n",
       "\n",
       "       [[ 16,  20,  20],\n",
       "        [  0,   0,   0],\n",
       "        [ 18,   8,   0],\n",
       "        ...,\n",
       "        [123,  88,  55],\n",
       "        [119,  83,  50],\n",
       "        [122,  87,  57]],\n",
       "\n",
       "       [[ 25,  24,  21],\n",
       "        [ 16,   7,   0],\n",
       "        [ 49,  27,   8],\n",
       "        ...,\n",
       "        [118,  84,  50],\n",
       "        [120,  84,  50],\n",
       "        [109,  73,  42]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[208, 170,  96],\n",
       "        [201, 153,  34],\n",
       "        [198, 161,  26],\n",
       "        ...,\n",
       "        [160, 133,  70],\n",
       "        [ 56,  31,   7],\n",
       "        [ 53,  34,  20]],\n",
       "\n",
       "       [[180, 139,  96],\n",
       "        [173, 123,  42],\n",
       "        [186, 144,  30],\n",
       "        ...,\n",
       "        [184, 148,  94],\n",
       "        [ 97,  62,  34],\n",
       "        [ 83,  53,  34]],\n",
       "\n",
       "       [[177, 144, 116],\n",
       "        [168, 129,  94],\n",
       "        [179, 142,  87],\n",
       "        ...,\n",
       "        [216, 184, 140],\n",
       "        [151, 118,  84],\n",
       "        [123,  92,  72]]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = int(len(dataset)*0.9)\n",
    "valid_num = len(dataset) - train_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, validset = random_split(dataset, [train_num, valid_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "validloader = DataLoader(validset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct model\n",
    "-----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JxB0RIFZKvrP",
    "outputId": "935c198b-65d2-46f0-bea7-a4f6551041ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             448\n",
      "              ReLU-2           [-1, 16, 32, 32]               0\n",
      "         MaxPool2d-3           [-1, 16, 16, 16]               0\n",
      "            Conv2d-4           [-1, 32, 16, 16]           4,640\n",
      "              ReLU-5           [-1, 32, 16, 16]               0\n",
      "         MaxPool2d-6             [-1, 32, 8, 8]               0\n",
      "            Conv2d-7             [-1, 64, 8, 8]          18,496\n",
      "         MaxPool2d-8             [-1, 64, 4, 4]               0\n",
      "           Flatten-9                 [-1, 1024]               0\n",
      "           Linear-10                   [-1, 32]          32,800\n",
      "             ReLU-11                   [-1, 32]               0\n",
      "           Linear-12                   [-1, 10]             330\n",
      "================================================================\n",
      "Total params: 56,714\n",
      "Trainable params: 56,714\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.47\n",
      "Params size (MB): 0.22\n",
      "Estimated Total Size (MB): 0.70\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential()\n",
    "model.add_module('conv1',nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1))\n",
    "model.add_module('relu1',nn.ReLU())\n",
    "model.add_module('pool1',nn.MaxPool2d(2,2))\n",
    "model.add_module('conv2',nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1))\n",
    "model.add_module('relu2',nn.ReLU())\n",
    "model.add_module('pool2',nn.MaxPool2d(2,2))\n",
    "model.add_module('conv3',nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1))\n",
    "model.add_module('relu2',nn.ReLU())\n",
    "model.add_module('pool3',nn.MaxPool2d(2,2))\n",
    "model.add_module('flatten',nn.Flatten())\n",
    "model.add_module('fc1', nn.Linear(in_features=64*4*4, out_features=32))\n",
    "model.add_module('relu4', nn.ReLU())\n",
    "model.add_module('fc3', nn.Linear(in_features=32, out_features=10))\n",
    "\n",
    "summary(model,input_size=(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "sVFu4BykKytd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-02.\n"
     ]
    }
   ],
   "source": [
    "loss_ftn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
    "                                        lr_lambda=lambda epoch: 0.95 ** epoch,\n",
    "                                        last_epoch=-1,\n",
    "                                        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "bnWQPYfyK53N"
   },
   "outputs": [],
   "source": [
    "def train(net, trainloader, validloader, epochs, device, loss_ftn, optimizer, scheduler=None, temperature=None):\n",
    "    losses = []\n",
    "    accs = []\n",
    "    valid_losses = []\n",
    "    valid_accs = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        valid_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        valid_correct = 0\n",
    "        valid_total = 0\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = loss_ftn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = (correct/total)*100\n",
    "        losses.append(running_loss)\n",
    "        accs.append(accuracy)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in validloader:\n",
    "                images, labels = data\n",
    "\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # calculate outputs by running images through the network\n",
    "                outputs = net(images)\n",
    "                loss = loss_ftn(outputs, labels)\n",
    "\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "                # the class with the highest energy is what we choose as prediction\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                valid_total += labels.size(0)\n",
    "                valid_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        valid_accuracy = (valid_correct/valid_total)*100\n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_accs.append(valid_accuracy)\n",
    "\n",
    "        print('EPOCH %d Completed. \\n Training Loss: %.3f, Training Accuracy: %.2f, Validation Loss: %.3f, Validation Accuracy: %.2f \\n' \n",
    "              %(epoch+1, running_loss, accuracy, valid_loss, valid_accuracy))\n",
    "        \n",
    "        if temperature is not None:\n",
    "            net.update_temperature()\n",
    "            \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "                        \n",
    "    return losses, accs, valid_losses, valid_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "aSQNpDsDK7b7"
   },
   "outputs": [],
   "source": [
    "def test(net, testloader, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)\n",
    "\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 Completed. \n",
      " Training Loss: 811.126, Training Accuracy: 10.06, Validation Loss: 92.138, Validation Accuracy: 8.92 \n",
      "\n",
      "Adjusting learning rate of group 0 to 9.5000e-03.\n",
      "EPOCH 2 Completed. \n",
      " Training Loss: 810.734, Training Accuracy: 9.88, Validation Loss: 92.162, Validation Accuracy: 10.02 \n",
      "\n",
      "Adjusting learning rate of group 0 to 9.0250e-03.\n",
      "EPOCH 3 Completed. \n",
      " Training Loss: 810.723, Training Accuracy: 10.01, Validation Loss: 92.161, Validation Accuracy: 9.54 \n",
      "\n",
      "Adjusting learning rate of group 0 to 8.5737e-03.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/envs/mathdl/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/anaconda3/envs/mathdl/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/opt/anaconda3/envs/mathdl/lib/python3.8/site-packages/torch/__init__.py\", line 22, in <module>\n",
      "    from ._utils_internal import get_file_path, prepare_multiprocessing_environment, \\\n",
      "  File \"/opt/anaconda3/envs/mathdl/lib/python3.8/site-packages/torch/_utils_internal.py\", line 4, in <module>\n",
      "    import tempfile\n",
      "  File \"/opt/anaconda3/envs/mathdl/lib/python3.8/tempfile.py\", line 43, in <module>\n",
      "    import shutil as _shutil\n",
      "  File \"/opt/anaconda3/envs/mathdl/lib/python3.8/shutil.py\", line 22, in <module>\n",
      "    import bz2\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 839, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 934, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1032, in get_data\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [46], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m EPOCHS\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 3\u001b[0m losses, accs, valid_losses, valid_accs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mloss_ftn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [44], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, trainloader, validloader, epochs, device, loss_ftn, optimizer, scheduler, temperature)\u001b[0m\n\u001b[1;32m     12\u001b[0m valid_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     13\u001b[0m valid_total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     16\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     18\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mathdl/lib/python3.8/site-packages/torch/utils/data/dataloader.py:352\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mathdl/lib/python3.8/site-packages/torch/utils/data/dataloader.py:294\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _SingleProcessDataLoaderIter(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mathdl/lib/python3.8/site-packages/torch/utils/data/dataloader.py:801\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    794\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m--> 801\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mathdl/lib/python3.8/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mathdl/lib/python3.8/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mathdl/lib/python3.8/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mathdl/lib/python3.8/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mathdl/lib/python3.8/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mathdl/lib/python3.8/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentinel \u001b[38;5;241m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS=10\n",
    "\n",
    "losses, accs, valid_losses, valid_accs = train(model, trainloader, validloader, EPOCHS, device, \n",
    "                                               loss_ftn, optimizer, scheduler=scheduler, temperature=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(EPOCHS)]\n",
    "plt.plot(x, losses, label='Training Loss')\n",
    "plt.plot(x, valid_losses, label='Validation Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train/Validation Loss Comparison')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(EPOCHS)]\n",
    "plt.plot(x, accs, label='Training Accuracy')\n",
    "plt.plot(x, valid_accs, label='Validation Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Train/Validation Accuracy Comparison')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 결과 : 5\n",
      "이 이미지 데이터의 정답 레이블 : 7\n"
     ]
    }
   ],
   "source": [
    "index = np.random.randint(10000)\n",
    "\n",
    "model.eval()  # 신경망을 추론 모드로 전환\n",
    "data = X_test[index]\n",
    "data = data.view([-1,3,32,32])\n",
    "output = model(data)  # 데이터를 입력하고 출력을 계산\n",
    "_, predicted = torch.max(output.data, 1)  # 확률이 가장 높은 레이블이 무엇인지 계산\n",
    "\n",
    "print(\"예측 결과 : \" + str(predicted.item()))\n",
    "print(\"이 이미지 데이터의 정답 레이블 : \" + str(y_test[index].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training\n",
    "-----\n",
    "We can test the model before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NBTyrwJUK9iv",
    "outputId": "b6f2596b-8c7a-4e0e-d4f5-e23f763d29ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "테스트 데이터에서 예측 정확도: 1000/10000 (10.00%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6BYZnrHiMknN",
    "outputId": "f25ab683-4f23-41e6-eb77-fcc2e58b5dd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1：완료\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 4170/10000 (41.70%)\n",
      "\n",
      "epoch2：완료\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 4475/10000 (44.75%)\n",
      "\n",
      "epoch3：완료\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 4903/10000 (49.03%)\n",
      "\n",
      "epoch4：완료\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 5091/10000 (50.91%)\n",
      "\n",
      "epoch5：완료\n",
      "\n",
      "\n",
      "테스트 데이터에서 예측 정확도: 5114/10000 (51.14%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "MAX_ITERATION=5\n",
    "for epoch in range(MAX_ITERATION):\n",
    "    train(epoch)\n",
    "    acc.append(test())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "Rx3WD5hcMzHB",
    "outputId": "5527b01c-9e69-42af-d1d9-ed1be7b93fc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2373e86b3a0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the model with data in testset\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 결과 : 7\n",
      "이 이미지 데이터의 정답 레이블 : 7\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # 신경망을 추론 모드로 전환\n",
    "data = X_test[index]\n",
    "data = data.view([-1,3,32,32])\n",
    "output = model(data)  # 데이터를 입력하고 출력을 계산\n",
    "_, predicted = torch.max(output.data, 1)  # 확률이 가장 높은 레이블이 무엇인지 계산\n",
    "\n",
    "print(\"예측 결과 : \" + str(predicted.item()))\n",
    "print(\"이 이미지 데이터의 정답 레이블 : \" + str(y_test[index].item()))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "MathDLstudy",
   "language": "python",
   "name": "mathdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b45ccf6fd3c8427b2d1b5e880d896f46770117107f616a4b6b7de4d4387dfaf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
