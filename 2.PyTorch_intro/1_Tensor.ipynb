{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Be29UUjrtYv9"
   },
   "source": [
    "Pytorch vs Tensorflow\n",
    "=======\n",
    "When we run to deep learning code, we use either Tensorflow pakage or Pytorch pakage.\n",
    "\n",
    "Recently, the number of papers with Pytorch is larger than the number of papers with Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3c7-xrs482s"
   },
   "source": [
    "Adaptability with Numpy pakage\n",
    "---------\n",
    "Tensorflow pakage is adaptable with Numpy pakage. However, Pytorch pakage isn't.\n",
    "\n",
    "When we use Pytorch pakage, we need to change type of data. (Tensor not Numpy array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SyLDMHP45DOZ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HqyEt_fC76Gp"
   },
   "outputs": [],
   "source": [
    "a = np.ones((1,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qfXgfBc1pSym",
    "outputId": "e1bea6cd-20da-41c1-906b-2a57439331ad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-21 10:15:21.005189: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-10-21 10:15:21.005456: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n",
       "array([[ 1.1699158 , -0.00213276,  0.12879065,  0.8911258 ,  1.2355055 ,\n",
       "        -0.26317134, -0.32644525, -0.30497113, -0.8705528 , -0.7665633 ,\n",
       "        -2.0725513 , -0.7568933 , -0.9928194 ,  0.04059547, -1.1255735 ,\n",
       "        -1.2792699 ]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tf =  tf.keras.models.Sequential()\n",
    "model_tf.add(tf.keras.Input(25,))\n",
    "model_tf.add(tf.keras.layers.Dense(16))\n",
    "model_tf(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "k9DHiMSupcwJ"
   },
   "outputs": [],
   "source": [
    "fc1_torch = nn.Linear(25,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "pO7f1s8dqFwc",
    "outputId": "eb17eb54-49e4-4f12-f02e-46a2ad750eed"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfc1_torch\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mathdl/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mathdl/lib/python3.8/site-packages/torch/nn/modules/linear.py:93\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mathdl/lib/python3.8/site-packages/torch/nn/functional.py:1688\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m([\u001b[38;5;28mtype\u001b[39m(t) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Tensor \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tens_ops]) \u001b[38;5;129;01mand\u001b[39;00m has_torch_function(tens_ops):\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(linear, tens_ops, \u001b[38;5;28minput\u001b[39m, weight, bias\u001b[38;5;241m=\u001b[39mbias)\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1689\u001b[0m     \u001b[38;5;66;03m# fused op is marginally faster\u001b[39;00m\n\u001b[1;32m   1690\u001b[0m     ret \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39maddmm(bias, \u001b[38;5;28minput\u001b[39m, weight\u001b[38;5;241m.\u001b[39mt())\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "fc1_torch(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bqh8q3bEDbhA",
    "outputId": "04dbd743-0632-45aa-a4ec-f0e6ffccb8af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1.]]\n",
      "<class 'numpy.ndarray'>\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1.]])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "a = np.ones((1,25))\n",
    "tensor_a = torch.tensor(a, dtype = torch.float32) # Numpy -> Tensor\n",
    "print(a)\n",
    "print(type(a))\n",
    "print(tensor_a)\n",
    "print(type(tensor_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "poZ60h0HDc-w",
    "outputId": "719df276-36bc-4e70-91e1-e564cfe2f7eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1812,  0.0865, -0.1581, -0.1831,  0.6724, -0.6289,  0.7905,  0.3346,\n",
       "         -0.2435,  0.3043,  0.7311,  0.0699,  0.6417,  0.3986,  0.8563,  0.7830]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fc1_torch = nn.Linear(25,16)\n",
    "fc1_torch(tensor_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfvUXspU-lEH"
   },
   "source": [
    "Tensor\n",
    "=======\n",
    "Tensor datatype is similar with Numpy array datatype.\n",
    "\n",
    "We can operate tensor with similar code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QtrAd24-_uOW",
    "outputId": "082aeda1-7fa4-4093-b31a-cd1daa4e44cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([1, 25])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of tensor: {tensor_a.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor_a.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor_a.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Tensor from Numpy array\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.41502811 -0.75050849  0.66057438  0.59845438]\n",
      " [-0.05399175 -1.42132401 -1.58212274 -0.64953701]\n",
      " [ 1.70176767 -0.17360025 -0.49828159 -0.11445542]]\n",
      "<class 'numpy.ndarray'>\n",
      "tensor([[-1.4150, -0.7505,  0.6606,  0.5985],\n",
      "        [-0.0540, -1.4213, -1.5821, -0.6495],\n",
      "        [ 1.7018, -0.1736, -0.4983, -0.1145]], dtype=torch.float64)\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "arr_np = np.random.randn(3,4)\n",
    "print(arr_np)\n",
    "print(type(arr_np))\n",
    "arr_tensor = torch.from_numpy(arr_np)\n",
    "print(arr_tensor)\n",
    "print(type(arr_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Tensor with random value or constant value\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.6846, 0.2368, 0.3512],\n",
      "        [0.7496, 0.3276, 0.0833]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)     # Simliar to np.random.rand(shape)\n",
    "ones_tensor = torch.ones(shape)     # Similar to np.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)   # Similar to np.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Device setup\n",
    "--------\n",
    "Each tensor has a device which is stored on. ('cpu' or 'cuda')\n",
    "\n",
    "To operate two (or more) tensors, devices must be same. Furthermore neural network or model must be same.\n",
    "\n",
    "![error_screenshot](./error.JPG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1.6846, 1.2368, 1.3512],\n",
      "        [1.7496, 1.3276, 1.0833]])\n"
     ]
    }
   ],
   "source": [
    "# We move our tensor to the GPU if available\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    rand_tensor = tensor.to(\"cuda\")\n",
    "\n",
    "print(zeros_tensor + ones_tensor)\n",
    "print(rand_tensor + ones_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing and Slicing\n",
    "-----\n",
    "We can indexing or slicing tensors similary to Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(5, 5)\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[..., -1]}\")\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine tensors\n",
    "-----\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "tensor_l = torch.ones(2,3)\n",
    "tensor_r = torch.zeros(2,2)\n",
    "tensor_combined = torch.cat([tensor_l, tensor_r], dim=1)\n",
    "print(tensor_l)\n",
    "print(tensor_r)\n",
    "print(tensor_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWrbCjoyCyVO"
   },
   "source": [
    "Arithmetic operations\n",
    "-------\n",
    "Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eSGUK9BYAyVt",
    "outputId": "bf64c377-fccd-4078-9c39-4cc016482839"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_a)\n",
    "print(tensor_a +1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUOgDQo8C0qD"
   },
   "source": [
    "Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ww0OQ0ERB_5o",
    "outputId": "96fd607d-f0ab-4219-e966-ec9cf9971529"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3828, 0.5420, 0.6608],\n",
      "        [0.9150, 0.9756, 0.9202]])\n",
      "tensor([[0.4691, 0.4331, 0.2848, 0.7001],\n",
      "        [0.8825, 0.5670, 0.2898, 0.3171],\n",
      "        [0.0756, 0.3217, 0.9543, 0.9602]])\n",
      "tensor([[0.7078, 0.6857, 0.8967, 1.0744],\n",
      "        [1.3597, 1.2455, 1.4214, 1.8336]])\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.rand((2,3))\n",
    "tensor2 = torch.rand((3,4))\n",
    "tensor_prod = tensor1@tensor2\n",
    "print(tensor1)\n",
    "print(tensor2)\n",
    "print(tensor_prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor -> Other datatype(Numpy array or float)\n",
    "------\n",
    "Tensor -> Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6846, 0.2368, 0.3512],\n",
      "        [0.7496, 0.3276, 0.0833]])\n",
      "[[0.68463945 0.2368375  0.3511768 ]\n",
      " [0.74961644 0.32758498 0.08330113]]\n"
     ]
    }
   ],
   "source": [
    "print(rand_tensor)\n",
    "rand_arr = rand_tensor.numpy()\n",
    "print(rand_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor -> Float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4332)\n",
      "<class 'torch.Tensor'>\n",
      "2.4331562519073486\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "sum = rand_tensor.sum()\n",
    "print(sum)\n",
    "print(type(sum))\n",
    "num = sum.item()\n",
    "print(num)\n",
    "print(type(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "MathDLstudy",
   "language": "python",
   "name": "mathdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b45ccf6fd3c8427b2d1b5e880d896f46770117107f616a4b6b7de4d4387dfaf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
